---
title             : "The role of experience in disambiguation during early word learning"
shorttitle        : "Disambiguation during early word learning"

author: 
  - name          : "Molly Lewis"
    affiliation   : "1, 6"
    corresponding : yes    # Define only one corresponding author
    address       : "Postal address"
    email         : "my@email.com"
  - name          : "Veronica Cristiano"
    affiliation   : "2"
  - name          : "Brenden Lake"
    affiliation   : "3"
  - name          : "Tammy Kwan"
    affiliation   : "4"
  - name          : "Michael C. Frank"
    affiliation   : "5"
  
affiliation:
  - id            : "1"
    institution   : "University of Chicago"
  - id            : "2"
    institution   : "Gallaudet University"
  - id            : "3"
    institution   : "New York University"
  - id            : "4"
    institution   : "Cognitive Toybox, Inc."
  - id            : "5"
    institution   : "Stanford University"
  - id            : "6"
    institution   : "University of Wisconsin, Madison"

author_note: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract: |
  Enter abstract here. Each new line herein must be indented, like this line.
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["references.bib"]

figsintext        : no
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : yes

lang              : "english"
class             : "man"
output            : papaja::apa6_pdf
---

```{r load_packages, include = FALSE, echo = FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(cache=TRUE, echo = FALSE, message = FALSE, warning = FALSE)

library(papaja)
library(tidyverse)
library(langcog)
library(ggthemes)
library(lme4)
library(knitr)
```

```{r analysis_preferences}
# Seed for random number generation
set.seed(42)
```


# Introduction

A central property of language is that each word in the lexicon maps to a unique concept, and each concept maps to a unique word [@clark1987principle]. Like other important regularities in language (e.g. grammatical categories), children cannot directly observe this general property. Instead, they must learn to use language in a way that is consistent with the generalization on the basis of evidence about only specific word-object pairs. 

Even very young children behave in a way that is consistent with this one-to-one regularity in language. Evidence for this claim comes from what is known as the "disambiguation" effect. In a typical demonstration of this effect [@markman1988], children are presented with a novel and familiar object (e.g., a whisk and a ball), and are asked to identify the referent of a novel word ("Show me the dax"). Children in this task tend to choose the novel object as the referent,  behaving in a way that is consistent with the one-to-one word-concept regularity in language across a wide range of ages and experimental paradigms [@mervis1994two;@golinkoff1994early;@markman2003;@halberda2003development;@bion2012fast].

This effect has received much attention in the word learning literature because the ability to identify the meaning of a word in ambiguous contexts is, in essence, the core problem of word learning. That is, given any referential context, the meaning of a word is underdetermined [@quine1960], and the challenge for the world learner is to identify the referent of the word within this ambiguous context. Critically, the ability to infer that a novel word maps to a novel object makes the problem much easier to solve. For example, suppose a child hears the novel word ``kumquat" while in the produce aisle of the grocery store. There are an infinite number of possible meanings of this word given this referential context, but the child's ability to correctly disambiguate would lead her to rule out all meanings for which she already had a name. With this restricted hypothesis space, the child is  more likely to identify the correct referent than if   all objects in the context were considered as possible referents. 

What are the cognitive processes underlying this effect? There are broadly two proposals in the literature. Under one proposal, Markman and colleagues [@markman1988, @markman2003] suggest that children have a constraint on the types of lexicons considered when learning the meaning of a new word -- a "mutual exclusivity constraint."  With this constraint, children are biased to consider only those lexicons that have a one-to-one mapping between words and objects. Importantly, this constraint can be overcome in cases where it is incorrect (e.g. property names),  but it nonetheless serves to restrict the set of lexicons initially entertained when learning the meaning of a novel word. Under this view, then, the disambiguation effect emerges from a general constraint on the structure of lexicons.

Under a second proposal, the disambiguation effect is argued to result from  online inferences made within the referential context  [@clark1987principle, @diesendruck2001]. In particular, Clark suggests that the disambiguation effect is due to two pragmatic assumptions held by speakers. The first assumption is that speakers within the same speech community use the same words to refer to the same objects ("Principle of Conventionality"). The second assumption is that different linguistic forms refer to different meanings ("Principle of Contrast"). In the disambiguation task described above, then, children might reason (implicitly) as follows: You used a word I've never heard before. Since, presumably we both call a ball "ball" and if you'd meant the ball you would have  said "ball," this new word must refer to the new object. Thus, under this account, the disambiguation effect emerges not from a higher-order constraint on the structure of lexicons, but instead from in-the-moment inferences using general pragmatic principles.

These two proposals have traditionally been viewed as competing explanations of the disambiguation effect. Research in this area has consequently focused on identifying empirical tests that can distinguish between these two theories. For example, @diesendruck2001 compare performance on a disambiguation task when children are told a novel fact about an object relative to a novel referential label. They found that children disambiguated in both conditions and argued on grounds of parsimony that the same pragmatic mechanism was likely to be responsible for both inferences. More recent evidence contradicts this view: tests of children with autism, who are known to have impairments in pragmatic reasoning find comparable performance on the disambiguation task between typically developing children and children with autism [@preissler2005role;@de2011mutual]. This result provides some evidence for the view that disambiguation is due to a domain-specific lexical constraint.

We suggest this competing-alternatives approach to the disambiguation effect should be reconsidered.  In a disambiguation task, learners may be making use of both general knowledge about how the lexicon is structured as well as information about the pragmatic or inferential structure of the task. Both of these constraints would then support children's inferences. In other words, these two classes of theories may be describing distinct, complimentary mechanisms that each contribute to a single empirical phenomenon with their weights in any given task determined by children's age and language experience, the nature of the pragmatic situation, and other task-specific factors. 


ME is important

ME is controversial 

What do we even call it? 

What's the goal of this paper.

## Theoretical views of "mutual exclusivity"

### Constraint and bias accounts

ME

N3C


### Probabilistic accounts

Regier

McMurray

Frank Goodman Tenenbaum

Fazly


### Over-hypothesis accounts


Lewis & Frank (2013)


### Pragmatic accounts

Clark?

In the moment

Learned pragmatics 

## Theory-constraining findings

NN vs. NF

Speaker-change studies

Autism 

Bilingualism

Fast mapping + no retention

Developmental change (halberda)



## Synthesis

These are definitely features of a successful account:
Timescales
- must be one "in the moment" 
- and one longer-term learned mechanism

Experience

Probabilistic representations

Could be the case also that it's a mixture of pragmatic, etc.


## The current study

Gather evidence on strength of finding

Test emergent relationship to vocabulary (E1)

Test causal relationship to representation strength (E2)

Re-evaluate

# Meta-analysis


## Methods


## Results


## Bilingualism


## Autism Spectrum Disorders



# Experiment 1: ME and Vocabulary


## Methods

We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study. <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

### Participants

Children were recruited at the Childrenâ€™s Discovery Museum of San Jose. Children were asked if they would be willing to play an iPad game with the experimenter and were informed that they could stop playing at any time. Children first completed two tasks adapted to iPad; one probing their vocabulary size and one mutual exclusivity inference task. Included in analyses are 166 children out of a planned sample of 160 participants. We ran 62 additional children, who were excluded from analysis based on planned exclusion criteria of low English language exposure (less than or equal to 75%), outside the age range of 24-48 month, children who do not give correct answers on > 50% of familiar noun (control) trials, or < 100% of trials completed. Included in our sample were 97 females and 69 males.

### Stimuli

Mutual exclusivity inference task was comprised of 19 trials total; three practice trials of Familiar-Familiar (FF) nouns and 16 experimental trials. Experimental trials consisted of Novel-Familiar (NF), and Novel-Novel (NN) noun pairings. Of the pictures presented in the task, 14 objects were familiar and 24 objects were novel. The task included 8 control trials, equally split between NN noun pairings (C-NN) and NF noun pairings (C-NF) given in random order. Children who did not give correct answers on 50% of control trials were excluded from the final sample. The remaining 8 trials were divided equally between NN and NF trials.

The general format of the vocabulary assessment comprised of a 4 image display and a verbal prompt. Two practice trials were administered, followed by 20 experimental trials. Experimental trials included a fixed set of 20 developmentally appropriate words taken from the Pearson Peabody Vocabulary Test. These words were taken from 9 different domains, including professions, food, outside things, instruments, animals, classroom, shapes, verbs, and household items.

### Procedure

Sessions took place individually in a small testing room away from the museum floor. In the ME inference task, the experimenter introduced them to "Mr. Fox," a cartoon character who wanted to play a guessing game. The experimenter explained that Mr. Fox would tell them the name of the object they had to find, so they had to listen carefully. Children then saw 3 practice trials with two commonly known objects (i.e. cup and cookie). If the participant chose incorrectly for this practice trial, the audio would correct them and allow the participant to choose again. After the practice trials were completed, the task proceeded to run 16 test trials. Reaction times were measured from the onset of the target word. Children could only make one selection. The vocabulary task displayed 4 images randomly selected from the fixed bank of 22 images. Participants were prompted to choose one object. Again, reaction times were measured from the onset of the target word and children could only make one selection.


### Data analysis
We used `r cite_r("r-references.bib")` for all our analyses.


## Results and Discussion

Could be specific strength of particular word in the NF pairing

but we also get it for NN trials alone



# Experiment 2: ME and Familiarity

```{r}
e2 <- read_csv("../data-me_exp/experimental_data_cleaned.csv")  %>%
  mutate(age_group = floor(age_mo/12),
         err_type = ifelse(is.na(correct), "no choice", err_type), 
         err = ifelse(is.na(correct), 1, err))
```

## Methods

We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study. <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

### Participants

```{r}
e2_subs <- e2 %>%
  group_by(sub_num, age_group) %>%
  summarise(age_mo = age_mo[1], 
            n = n(), 
            err = sum(err)) 

e2_subs %>%
  group_by(age_group) %>%
  summarise(mean_age = mean(age_mo), 
            n = n()) %>%
  papaja::apa_table(caption = "Demographics of children in Experiment 2.")
```

We planned a total sample of 108 children, 12 per between-subjects labeling condition, and 36 total in each one-year age gorup. Our final sample was `r nrow(e2_subs)` children, ages `r min(e2_subs$age.mo)` -- `r max(e2_subs$age.mo)` months, recruited from the floor of the Boston Children's Museum. Children were randomly assigned to the one-label, two-label, or three label condition, with the total number of children in each age group and condition ranging between 10 and 13.  

### Materials

Materials were the set of novel objects used in @demarchena2011, consisting of unusual household items (e.g., a yellow plastic drain catcher) or other small, lab-constructed stimuli (e.g., a plastic lid glued to a popsicle stick). Items were distinct in color and shape. 

### Procedure

Each child completed four trials. Each trial consisted of a training and a test phase in a "novel-novel" disambiguation task [@demarchena2013]. In the training phase, the experimenter presented the child with a novel object, and explicitly labeled the object with a novel label 1, 2, or 3 times ("Look at the *dax*"), and contrasted it with a second novel object ("And this one is cool too") to ensure equal familiarity. In the test phase, the child was asked to point to the object referred to by a second novel label ("Can you show me the *zot*?"). Number of labels used in the training phase was manipulated between subjects. There were eight different novel words and objects. Object presentation side, object, and word were counterbalanced across children. 

### Data analysis

We followed the same analytic approach as we registered in Experiment 1, though data were collected chronologically earlier for Experiment 2. Responses were coded as correct if participants selected the novel object at test. A small number of trials were coded as having parent or sibling interference, experimenter error, or a child who recognized the target object, chose both objects, or did not make a choice. These trials were excluded from further analyses; all trials were removed for two children for whom there was parent or sibling interference on every trial. The analysis we report here is consistent with that used in @lewis2013, though there are some slight numerical differences due to reclassification of exclusions. 

```{r}
e2 %>%
  filter(err == 1) %>%
  group_by(err_type) %>%
  summarise(n = n(), 
            pct = n() / nrow(e2)) %>%
  apa_table()

e2_clean <- filter(e2, !err)
```


## Results and Discussion

 As predicted, children showed a stronger disambiguation effect as the number of training labels increased, and as noise decreased with age.

```{r}
mss <- e2_clean %>%
  group_by(age_group, cond, sub_num) %>%
  summarise(correct = mean(correct)) 

ms <- mss %>%
  multi_boot_standard(col = "correct", na.rm=TRUE)

ggplot(ms, aes(x = factor(age_group), y = mean, col = cond)) + 
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper), 
                  position = position_dodge(width = .1)) + 
  geom_line(aes(group = cond)) +
  geom_hline(yintercept = .5, lty = 2) + 
  xlab("Age (years)") + 
  ylim(0,1) + 
  ylab("Proportion correct") + 
  scale_color_solarized(name = "Condition") + 
  theme_few()
```

```{r}
e2_clean$age_mo_c <- scale(e2_clean$age_mo, 
                           scale = FALSE, center = TRUE)
e2_clean$times_labeled_c <- scale(e2_clean$times_labeled, 
                                  scale = FALSE, center = TRUE)

mod <- glmer(correct ~ age_mo_c * times_labeled_c  + 
               (times_labeled_c | sub_num), 
      family = "binomial", 
      data = e2_clean)

summary(mod)$coefficients %>%
  apa_table()


```

We analyzed the results using a logistic mixed model to predict correct responses with age, number of labels, and their interaction as fixed effects, and participant as a random effect. We centered both age and number of labels for interpretability of coefficients. Model results are shown in Table XYZ. There was a significant effect of age such that older children showed a stronger disambiguation bias and a  significant effect of number of labels, such that more training labels led to stronger disambiguation, but the interaction between age and number of labels was not significant.


# General Discussion


\newpage

# References
```{r create_r-references}
r_refs(file = "references.bib")
```

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

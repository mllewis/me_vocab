---
title             : "The role of experience in disambiguation during early word learning"
shorttitle        : "Disambiguation during early word learning"

author: 
  - name          : "Molly Lewis"
    affiliation   : "1, 6"
    corresponding : yes    # Define only one corresponding author
    address       : "Postal address"
    email         : "my@email.com"
  - name          : "Veronica Cristiano"
    affiliation   : "2"
  - name          : "Brenden Lake"
    affiliation   : "3"
  - name          : "Tammy Kwan"
    affiliation   : "4"
  - name          : "Michael C. Frank"
    affiliation   : "5"
  
affiliation:
  - id            : "1"
    institution   : "University of Chicago"
  - id            : "2"
    institution   : "Gallaudet University"
  - id            : "3"
    institution   : "New York University"
  - id            : "4"
    institution   : "Cognitive Toybox, Inc."
  - id            : "5"
    institution   : "Stanford University"
  - id            : "6"
    institution   : "University of Wisconsin, Madison"

author_note: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Data from Experiment 2 weer previously presented in the Proceedings of the Cognitive Science Society Conference in Lewis & Frank (2013). 

abstract: |
  Enter abstract here. Each new line herein must be indented, like this line.
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["references.bib"]

figsintext        : no
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : yes

lang              : "english"
class             : "man"
output            : papaja::apa6_pdf
---

```{r load_packages, include = FALSE, echo = FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(cache=TRUE, echo = FALSE, message = FALSE, warning = FALSE)

library(papaja)
library(tidyverse)
library(langcog)
library(ggthemes)
library(lme4)
library(knitr)
library(feather)
library(forcats)
library(ggrepel)
```

```{r analysis_preferences}
# Seed for random number generation
set.seed(42)
```


# Introduction

A central property of language is that each word in the lexicon maps to a unique concept, and each concept maps to a unique word [@clark1987principle]. Like other important regularities in language (e.g., grammatical categories), children cannot directly observe this general property. Instead, they must learn to use language in a way that is consistent with the generalization on the basis of evidence about only specific word-object pairs. 

Even very young children behave in a way that is consistent with this one-to-one regularity in language. Evidence for this claim comes from what is known as the "disambiguation" or "mutual exclusivity" (ME) effect (we return to the issue of nomenclaturer below). In a typical demonstration of this effect [@markman1988], children are presented with a novel and familiar object (e.g., a whisk and a ball), and are asked to identify the referent of a novel word ("Show me the dax"). Children in this task tend to choose the novel object as the referent, behaving in a way that is consistent with the one-to-one word-concept regularity in language across a wide range of ages and experimental paradigms [@mervis1994two;@golinkoff1994early;@markman2003;@halberda2003development;@bion2012fast].

This effect has received much attention in the word learning literature because the ability to identify the meaning of a word in ambiguous contexts is, in essence, the core problem of word learning. That is, given any referential context, the meaning of a word is underdetermined [@quine1960], and the challenge for the world learner is to identify the referent of the word within this ambiguous context. Critically, the ability to infer that a novel word maps to a novel object makes the problem much easier to solve. For example, suppose a child hears the novel word "kumquat" while in the produce aisle of the grocery store. There are an infinite number of possible meanings of this word given this referential context, but the child's ability to correctly disambiguate would lead her to rule out all meanings for which she already had a name. With this restricted hypothesis space, the child is more likely to identify the correct referent than if all objects in the context were considered as possible referents. 

Despite -- or perhaps due to -- the attention that the ME effect has received, there is little consensus regarding the cognitive mechanisms underlying it. Does it stem from a basic inductive bias on children's learning abilities ("bias accounts," see below), a learned regularity about the structure of language ("overhypothesis accounts"), reasoning about the goals of communication in context ("pragmatic accounts"), or perhaps some mixture of these? The goal of the current manuscript is to lay out these possibilities and discuss the state of the evidence. Along the way we present a meta-analysis of the extant empirical literature. We then present two new, relatively large-sample developmental experiments that investigate the dependence of children's ME inferences on vocabulary (Experiment 1) and experience with particular words (Experiment 2). We end by discussing the emergence of ME inferences in a range of computational models of word learning.  We conclude that:

1. Explanations of ME are not themselves mutually exclusive and likely more than one is at play;
2. The balance of responsibility for behavior likely changes developmentally, with basic biases playing a greater role for younger children and learned overhypotheses playing a greater role for older children. 
3. All existing accounts put too little emphasis on the role of experience and strength of representation; this lack of explicit theory in many cases precludes definitive tests. 
4. ME inferences are distinct from learning.

## A note on terminology. 

@markman1988's seminal paper coined the term "mutual exclusivity," which was meant to label the theoretical proposal that "children constrain word meanings by assuming at first that words are mutually exclusive -- that each object will have one and only one label." [@markman1990, p.66]. That initial paper also adopted a task used by a variety of previous authors [CHECK THESE CITES, including @golinkoff1985;@hutchinson1986;@vincent-smith1974], in which a novel and a familiar object were presented to children in a pair and the child was asked to "show me the *x*," where *x* was a novel label. Since then, informal discussions have used the same name for the paradigm and effect (selecting the novel object as the referebnt of the novel word) as well as the theoretical account (an early assumption or bias).
This conflation of paradigm/effect with theory is problematic, as other authors who have argued against the theoretical account then are in the awkward position of rejecting the name for the paradigm they have used. Other labels (e.g. "disambiguation" or "referent selection" effect) are not ideal, however, because they are not as specific do not refer as closely to the previous literature. Here we adopt the label "mutual exclusivity" (ME) for the general family of paradigms and associated effects, *without* prejudgment of the theoretical account of these effects. 

ME has also been referred to as "fast mapping." This conflation is confusing at best. In an early study, @carey1978 presented children with an incidental word learning scenario by using a novel color term to refer to an object: "You see those two trays over there. Bring me the *chromium* one. Not the red one, the *chromium* one." Those data [and subsequent replications, e.g. @markson1997] showed that this exposure was enough to establish some representation of the link between phonological form and meaning that endured over an extended period; a subsequent clarification of this theoretical claim emphasized that these initial meanings are partial [@carey2010]. Importantly, however, demonstrations of retention relied on learning in a case where there was a contrastive presentation of the word with a larger set of contrastive cues [@carey1978] or pre-exposure to the object [@markson1997]. 



## Theoretical views of "mutual exclusivity"

What are the cognitive processes underlying this effect? A range of  proposals in the literature. 


### Constraint and bias accounts

Under one proposal, Markman and colleagues [@markman1988, @markman2003] suggest that children have a constraint on the types of lexicons considered when learning the meaning of a new word -- a "mutual exclusivity constraint."  With this constraint, children are biased to consider only those lexicons that have a one-to-one mapping between words and objects. Importantly, this constraint can be overcome in cases where it is incorrect (e.g. property names),  but it nonetheless serves to restrict the set of lexicons initially entertained when learning the meaning of a novel word. Under this view, then, the disambiguation effect emerges from a general constraint on the structure of lexicons. This constraint is assumed to be innate or early emerging.


N3C


### Probabilistic accounts

Regier

McMurray

Frank Goodman Tenenbaum

Fazly


### Over-hypothesis accounts


Lewis & Frank (2013)


### Pragmatic accounts


The disambiguation effect is argued to result from  online inferences made within the referential context  [@clark1987principle, @diesendruck2001]. In particular, Clark suggests that the disambiguation effect is due to two pragmatic assumptions held by speakers. The first assumption is that speakers within the same speech community use the same words to refer to the same objects ("Principle of Conventionality"). The second assumption is that different linguistic forms refer to different meanings ("Principle of Contrast"). In the disambiguation task described above, then, children might reason (implicitly) as follows: You used a word I've never heard before. Since, presumably we both call a ball "ball" and if you'd meant the ball you would have  said "ball," this new word must refer to the new object. Thus, under this account, the disambiguation effect emerges not from a higher-order constraint on the structure of lexicons, but instead from in-the-moment inferences using general pragmatic principles.

These two proposals have traditionally been viewed as competing explanations of the disambiguation effect. Research in this area has consequently focused on identifying empirical tests that can distinguish between these two theories. For example, @diesendruck2001 compare performance on a disambiguation task when children are told a novel fact about an object relative to a novel referential label. They found that children disambiguated in both conditions and argued on grounds of parsimony that the same pragmatic mechanism was likely to be responsible for both inferences. More recent evidence contradicts this view: tests of children with autism, who are known to have impairments in pragmatic reasoning find comparable performance on the disambiguation task between typically developing children and children with autism [@preissler2005role;@de2011mutual]. This result provides some evidence for the view that disambiguation is due to a domain-specific lexical constraint.

Clark?

In the moment

Learned pragmatics 

### Logical inference accounts

@halberda2003


## Theory-constraining findings

NN vs. NF

Speaker-change studies

Autism 

Bilingualism

Fast mapping + no retention

Developmental change (halberda)



## Synthesis

These are definitely features of a successful account:
Timescales
- must be one "in the moment" 
- and one longer-term learned mechanism

Experience

Probabilistic representations

Could be the case also that it's a mixture of pragmatic, etc.

We suggest this competing-alternatives approach to the disambiguation effect should be reconsidered.  In a disambiguation task, learners may be making use of both general knowledge about how the lexicon is structured as well as information about the pragmatic or inferential structure of the task. Both of these constraints would then support children's inferences. In other words, these two classes of theories may be describing distinct, complimentary mechanisms that each contribute to a single empirical phenomenon with their weights in any given task determined by children's age and language experience, the nature of the pragmatic situation, and other task-specific factors. 



## The current study

Gather evidence on strength of finding

Test emergent relationship to vocabulary (E1)

Test causal relationship to representation strength (E2)

Re-evaluate


# Meta-analysis

```{r}


ma_raw <- read_feather("../MA/data/mutual_exclusivity") %>%
  select(c(1, 3, 6, 12, 14, 15, 18, 20, 22:24, 
           29:30, 52,53, 95, 96, 97, 98, 100, 101)) %>%
  mutate_if(is.character, as.factor)

AVG_MONTH <- 30.43688
ma_c <- ma_raw %>%
  mutate(mean_age = mean_age_1/AVG_MONTH) %>%
  filter(infant_type2 != "adults",
         study_ID != "sugimura1997") # no variability
```


## Methods


### Search strategy
We conducted a forward search based on citations of Markman and Wachtel (1988) in Google Scholar, and by using the keyword combination 'mutual exclusivity' in Google Scholar (September 2013). We also identified additional papers that were cited from this initial list. We then narrowed our sample to the subset that used one of two paradigms: (1) the canonical experimental paradigm for testing disambiguation behavior (an experimenter says a novel word in the context of a familiar object and a novel object, and the child guesses the intended referent; "Familiar-Novel"), or (2) a paradigm that exposed children to an an unambigous mapping of a novel label to a novel object, and then introduced a second novel object and asked children to identify the referent of a second novel label ("Novel-Novel"). We included conditions that included more than one familiar object. We then restricted our sample to only those that contained conditions that satisfied the following criteria: (a) participants were children, (b) referents were objects or pictures (not facts or object parts), (c)  no incongruent cues (e.g. eye gaze at familiar object), and (d) peer-reviewed. We included papers that measured responses either through forced-choice pointing or eye-tracking. One paper [@sugimura1996factors] was exscluded because it reported no variability in participants' performance (all children succeeded), and thus we could not compute an effect size. `r length(unique(ma_c$study_ID))` papers satisfied our criteria. 

### Coding
For each paper, we coded each relevant condition in each experiment separately, leading to  `r nrow(ma_c)` unique conditions in total. For each condition, we coded the paper metadata (citation) as well as several potential moderator variables: method (pointing or eyetracking), mean age of infants, participant population type (e.g., monolingual-typically-developing, ASD, etc.), and estimates of vocabulary size from the Words and Gestures form of the MacArthur-Bates Communicative Development Inventory when available [MCDI; @fenson1994variability, @fenson2007macarthur].

To estimate the effect size in each condition, we coded a number of quantitative variables: sample size, proportion novel-object selections, baseline (e.g., .5 in a 2-AFC paradigm), and standard deviations for novel object selections, t-statistic, and Cohen's d. For XX conditions, there was data were insufficient data reported in the main text to calculate an effect size (no means and standard deviations, t-statistic, or cohen's ds), but we were able to esimtate the means and standard deviations though measurement of barplots. 

### Statistical approach

We calculated d

For each paper, we coded each condition in each experiment separately with `r nrow(ma_c)` conditions total

For each 
Of this sample, `r  length(which(!is.na(ma_raw$d_calc)))` did not have 



 We identified 38 relevant papers and coded each condition in each paper for mean age, effect size (Cohen’s d) and CDI productive vocabulary, where reported. Effect size reflected the bias to select the novel object when presented with a novel label, relative to the familiar object. From the 38 total papers, there were 51 conditions in 20 papers for which statistical reporting was sufficient to calculate effect size. 

## Results

```{r}

```

```{r}
ma_plotting <- ma_c %>%
  mutate(es_type = ifelse(infant_type2 != "typical",
                          "Non-Typical Populations",
                          ifelse(ME_trial_type == "NN", 
                                 "Novel-Novel", "Novel-Familiar")),
         infant_type2_label = ifelse(infant_type2 == "typical", "", as.character(infant_type2)),
         infant_type2_label = fct_recode(infant_type2_label, 
                                         LT = "late_talkers", DHH = "deaf/hard-of-hearing", BL = "bilingual", TL = "trilingual" ))

novel_familiar_only <- ma_plotting %>%
  filter(infant_type2 == "typical",
         ME_trial_type == "FN") %>%
  select(d_calc, mean_age)

all_FN <- mutate(novel_familiar_only, es_type = "Novel-Familiar", line_group = 1) %>%
  bind_rows(mutate(novel_familiar_only, es_type = "Novel-Novel", line_group = 2) ) %>%
    bind_rows(mutate(novel_familiar_only, es_type = "Non-Typical Populations", line_group = 2) ) %>%
    mutate(es_type = fct_relevel(es_type, "Novel-Familiar", "Novel-Novel"))

ma_plotting %>%
 mutate(es_type = fct_relevel(es_type, "Novel-Familiar", "Novel-Novel")) %>%
  ggplot(aes(x = mean_age, y = d_calc)) +
    geom_point(aes(size = n_1, shape = ME_trial_type), alpha = .5) +
    #geom_text(aes(label = infant_type2_label)) +
    ggrepel::geom_text_repel(aes(label = infant_type2_label), box.padding = .5) +
    geom_hline(aes(yintercept = 0)) +
    facet_grid(~es_type, scale = "free_x") +
    geom_smooth(aes(linetype = as.factor(line_group)), 
                method = "lm", formula = y ~ log(x), data = all_FN, se = F) +
    scale_size_continuous(name="Sample size") +
  guides(linetype=FALSE) +
    xlab("Mean age (months)") +
    ylab("Estimated effect size (d)") +
    ggtitle("Meta-analysis") +
    theme_few() 
    #xlim(0, 65) 
```


## Bilingualism


## Autism Spectrum Disorders



# Experiment 1: ME and Vocabulary


## Methods

We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study. <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

### Participants

Children were recruited at the Children’s Discovery Museum of San Jose. Children were asked if they would be willing to play an iPad game with the experimenter and were informed that they could stop playing at any time. Children first completed two tasks adapted to iPad; one probing their vocabulary size and one mutual exclusivity inference task. Included in analyses are 166 children out of a planned sample of 160 participants. We ran 62 additional children, who were excluded from analysis based on planned exclusion criteria of low English language exposure (less than or equal to 75%), outside the age range of 24-48 month, children who do not give correct answers on > 50% of familiar noun (control) trials, or < 100% of trials completed. Included in our sample were 97 females and 69 males.

### Stimuli

Mutual exclusivity inference task was comprised of 19 trials total; three practice trials of Familiar-Familiar (FF) nouns and 16 experimental trials. Experimental trials consisted of Novel-Familiar (NF), and Novel-Novel (NN) noun pairings. Of the pictures presented in the task, 14 objects were familiar and 24 objects were novel. The task included 8 control trials, equally split between NN noun pairings (C-NN) and NF noun pairings (C-NF) given in random order. Children who did not give correct answers on 50% of control trials were excluded from the final sample. The remaining 8 trials were divided equally between NN and NF trials.

The general format of the vocabulary assessment comprised of a 4 image display and a verbal prompt. Two practice trials were administered, followed by 20 experimental trials. Experimental trials included a fixed set of 20 developmentally appropriate words taken from the Pearson Peabody Vocabulary Test. These words were taken from 9 different domains, including professions, food, outside things, instruments, animals, classroom, shapes, verbs, and household items.

### Procedure

Sessions took place individually in a small testing room away from the museum floor. In the ME inference task, the experimenter introduced them to "Mr. Fox," a cartoon character who wanted to play a guessing game. The experimenter explained that Mr. Fox would tell them the name of the object they had to find, so they had to listen carefully. Children then saw 3 practice trials with two commonly known objects (i.e. cup and cookie). If the participant chose incorrectly for this practice trial, the audio would correct them and allow the participant to choose again. After the practice trials were completed, the task proceeded to run 16 test trials. Reaction times were measured from the onset of the target word. Children could only make one selection. The vocabulary task displayed 4 images randomly selected from the fixed bank of 22 images. Participants were prompted to choose one object. Again, reaction times were measured from the onset of the target word and children could only make one selection.


### Data analysis

We used `r cite_r("r-references.bib")` for all our analyses.


## Results and Discussion

Could be specific strength of particular word in the NF pairing

but we also get it for NN trials alone



# Experiment 2: ME and Familiarity

```{r}
e2 <- read_csv("../data-me_exp/experimental_data_cleaned.csv")  %>%
  mutate(age_group = floor(age_mo/12),
         err_type = ifelse(is.na(correct), "no choice", err_type), 
         err = ifelse(is.na(correct), 1, err))
```

## Methods

We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study. <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

### Participants

```{r}
e2_subs <- e2 %>%
  group_by(sub_num, age_group) %>%
  summarise(age_mo = age_mo[1], 
            n = n(), 
            err = sum(err)) 

e2_subs %>%
  group_by(age_group) %>%
  summarise(mean_age = mean(age_mo), 
            n = n()) %>%
  papaja::apa_table(caption = "Demographics of children in Experiment 2.")
```

We planned a total sample of 108 children, 12 per between-subjects labeling condition, and 36 total in each one-year age gorup. Our final sample was `r nrow(e2_subs)` children, ages `r min(e2_subs$age.mo)` -- `r max(e2_subs$age.mo)` months, recruited from the floor of the Boston Children's Museum. Children were randomly assigned to the one-label, two-label, or three label condition, with the total number of children in each age group and condition ranging between 10 and 13.  

### Materials

Materials were the set of novel objects used in @de2011mutual, consisting of unusual household items (e.g., a yellow plastic drain catcher) or other small, lab-constructed stimuli (e.g., a plastic lid glued to a popsicle stick). Items were distinct in color and shape. 

### Procedure

Each child completed four trials. Each trial consisted of a training and a test phase in a "novel-novel" disambiguation task [@demarchena2013]. In the training phase, the experimenter presented the child with a novel object, and explicitly labeled the object with a novel label 1, 2, or 3 times ("Look at the *dax*"), and contrasted it with a second novel object ("And this one is cool too") to ensure equal familiarity. In the test phase, the child was asked to point to the object referred to by a second novel label ("Can you show me the *zot*?"). Number of labels used in the training phase was manipulated between subjects. There were eight different novel words and objects. Object presentation side, object, and word were counterbalanced across children. 

### Data analysis

We followed the same analytic approach as we registered in Experiment 1, though data were collected chronologically earlier for Experiment 2. Responses were coded as correct if participants selected the novel object at test. A small number of trials were coded as having parent or sibling interference, experimenter error, or a child who recognized the target object, chose both objects, or did not make a choice. These trials were excluded from further analyses; all trials were removed for two children for whom there was parent or sibling interference on every trial. The analysis we report here is consistent with that used in @lewis2013b, though there are some slight numerical differences due to reclassification of exclusions. 

```{r}
e2 %>%
  filter(err == 1) %>%
  group_by(err_type) %>%
  summarise(n = n(), 
            pct = n() / nrow(e2)) %>%
  apa_table()

e2_clean <- filter(e2, !err)
```


## Results and Discussion

 As predicted, children showed a stronger disambiguation effect as the number of training labels increased, and as noise decreased with age.

```{r}
mss <- e2_clean %>%
  group_by(age_group, cond, sub_num) %>%
  summarise(correct = mean(correct)) 

ms <- mss %>%
  multi_boot_standard(col = "correct", na.rm=TRUE)

ggplot(ms, aes(x = factor(age_group), y = mean, col = cond)) + 
  geom_hline(yintercept = .5, lty = 2) + 
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper), 
                  position = position_dodge(width = .1)) + 
  geom_line(aes(group = cond)) +
  xlab("Age (years)") + 
  ylim(0,1) + 
  ylab("Proportion correct") + 
  scale_color_solarized(name = "Condition", 
                        labels=c("1 label", "2 label", "3 label")) + 
  theme_few()
```

```{r}
e2_clean$age_mo_c <- scale(e2_clean$age_mo, 
                           scale = FALSE, center = TRUE)
e2_clean$times_labeled_c <- scale(e2_clean$times_labeled, 
                                  scale = FALSE, center = TRUE)

mod <- glmer(correct ~ age_mo_c * times_labeled_c  + 
               (times_labeled_c | sub_num), 
      family = "binomial", 
      data = e2_clean)

summary(mod)$coefficients %>%
  apa_table()


```

We analyzed the results using a logistic mixed model to predict correct responses with age, number of labels, and their interaction as fixed effects, and participant as a random effect. We centered both age and number of labels for interpretability of coefficients. Model results are shown in Table XYZ. There was a significant effect of age such that older children showed a stronger disambiguation bias and a  significant effect of number of labels, such that more training labels led to stronger disambiguation, but the interaction between age and number of labels was not significant.

# ME in Models of Word Learning

## Basic statistical biases ("explaining away")

@regier2001 model shows ME emergent

as noted by @frank2009, @yu2007 model (IBM machine translation model #1, @cite for that; subsequently adapted by @fazly2012) shows ME as well. 

this is because any conditional probability model will show the same effect

In other words, @markman1988's sense of a basic inductive bias will likely be present in a wide variety of different learning models. 

What is the experience-dependence of ME in these models? In the @frank2009 model, the strength of the ME response scales with the strength of the familiar word's mapping; the same thing is true for the other models presumably. 

Open question whether the actual differerence in a 2-year-olds' and a 4-year-olds' strength of representation of "ball" is what matters here?


@frank2009 model shows ME, in fact stronger than basic conditional probability. This is in part due to the use of the intention variable. 

As a side note, the @horst2007 no retention finding is shown in an even more pragmatic model: @smith2013 model shows ME with no retention (though explanation in that model is a little implausible "because the speaker might not be committed to that label and is just using it as a matter of convenience.")

Primary point: No support here for overhypothesis building, which is suggested by 1) the bilingualism results. In order to fit the bilingual data, in general we'd have to assume that strength of individual representations in monolinguals and bilinguals was a driver, and this seems unlikely. 2) no support for E1 vocab findings unless the entire developmental trend is due to strength of the familiar word representations. In general, the strong --- likely false --- claim from all of these models is that the individual representation of the familiar object strength is the only locus for developmental/population-related change.

@mcmurrray2012 model has ME emerge from the competition dynamics of a neural network. 

> Thus, the selection of the novel object is dependent on the learning rule, but not because the network needs to learn something about that object/word. Rather, the weights between the known word/objects and the unused lexical units must decay, and the weights between the novel ones must not in order to create a platform upon which real-time competition dynamics can select the right object. A different type of weight decay (for example, if all weights decayed on each epoch) would not preserve the right form of the weight matrix. However, learning is not the whole story: this pattern of connectivity could not be harnessed in situation time without the gradual settling process represented by the inhibition and feedback dynamics. Moreover, the model’s ability to learn from M.E. referent selection may also depend on this competition/feedback cycle. The model must select a single lexical unit and selectively amplify the novel object in order to eventually turn a word-referent link created during M.E. referent selection into a known word by associating the novel object with the novel word over many instances. Thus, while as a real-time process mutual exclusivity is likely to impact learning, it is really more the product of learning than a mechanism of it.

This proposal is complicated but might capture the global and local dynamics in Experiment 1 & 2 better than others. 

@zinserunderreview deal with bilingual data by adding a direct ME-related penalty, not letting it be emergent. 

# General Discussion


\newpage

# References
```{r create_r-references}
r_refs(file = "references.bib")
```

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

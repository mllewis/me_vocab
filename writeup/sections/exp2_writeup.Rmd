
# Experiment 2: Disambiguation Effect and Familiarity

In Experiment 2, we test a causal relationship between vocabulary size and the disambiguation effect by experimentally manipulating the strength of word knowledge. We do this by teaching participants a label for a novel object and varying the number of times the object is labeled. This manipulation allows us to vary children's certainty about the label for an object, with objects that have been labeled more frequently associated with high certainty about the label name. The newly, unabiguously labeled object then serves as the "familiar" object in a novel-novel trial. If the strength of vocabulary knowledge about the "familiar" object influences, the strength of the disambiguation effect, then we should expect a larger bias when the the familiar object has been labeled more frequently. We a pattern consistent with the prediction. 

```{r}
e2 <- read_csv("../../exp2/experimental_data_cleaned.csv")  %>%
  mutate(age_group = floor(age_mo/12),
         err_type = ifelse(is.na(correct), "no choice", err_type), 
         err = ifelse(is.na(correct), 1, err))
```

## Methods

We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study. <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

### Participants

```{r}
e2_subs <- e2 %>%
  group_by(sub_num, age_group) %>%
  summarise(age_mo = age_mo[1], 
            n = n(), 
            err = sum(err)) 

e2_subs %>%
  group_by(age_group) %>%
  summarise(mean_age = round(mean(age_mo),2), 
            n = n()) %>%
  kable( row.names = F,
        format = "latex",
        booktabs = TRUE,
        col.names = c("Age group", "Mean age (months)", "Sample size"))
  #papaja::apa_table(caption = "Demographics of children in Experiment 2.")
```

We planned a total sample of 108 children, 12 per between-subjects labeling condition, and 36 total in each one-year age gorup. Our final sample was `r nrow(e2_subs)` children, ages `r min(e2_subs$age.mo)` -- `r max(e2_subs$age.mo)` months, recruited from the floor of the Boston Children's Museum. Children were randomly assigned to the one-label, two-label, or three label condition, with the total number of children in each age group and condition ranging between 10 and 13.  

### Materials

Materials were the set of novel objects used in @de2011mutual, consisting of unusual household items (e.g., a yellow plastic drain catcher) or other small, lab-constructed stimuli (e.g., a plastic lid glued to a popsicle stick). Items were distinct in color and shape. 

### Procedure

Each child completed four trials. Each trial consisted of a training and a test phase in a "novel-novel" disambiguation task [@demarchena2011]. In the training phase, the experimenter presented the child with a novel object, and explicitly labeled the object with a novel label 1, 2, or 3 times ("Look at the *dax*"), and contrasted it with a second novel object ("And this one is cool too") to ensure equal familiarity. In the test phase, the child was asked to point to the object referred to by a second novel label ("Can you show me the *zot*?"). Number of labels used in the training phase was manipulated between subjects. There were eight different novel words and objects. Object presentation side, object, and word were counterbalanced across children. 

### Data analysis

```{r}
exclusions <- e2 %>%
  filter(err == 1) %>%
  count(err_type) 

e2_clean <- filter(e2, !err)
```


We followed the same analytic approach as we registered in Experiment 1, though data were collected chronologically earlier for Experiment 2. Responses were coded as correct if participants selected the novel object at test. A small number of trials were coded as having parent or sibling interference (*N* = `r filter(exclusions, err_type == "interference")$n`), experimenter error (*N* = `r filter(exclusions, err_type == "exp err")$n`), or a child who recognized the target object (*N* = `r filter(exclusions, err_type == "recog obj")$n`), chose both objects (*N* = `r filter(exclusions, err_type == "changed mind")$n`) or did not make a choice (*N* = `r filter(exclusions, err_type == "no choice")$n`). These trials were excluded from further analyses; all trials were removed for two children for whom there was parent or sibling interference on every trial. We centered both age and number of labels for interpretability of coefficients.  The analysis we report here is consistent with that used in @lewis2013b, though there are some slight numerical differences due to reclassification of exclusions. 

## Results and Discussion

As predicted, children showed a stronger disambiguation effect as the number of training labels increased, and as noise decreased with age.

```{r, fig.width=5, fig.height =3.5, fig.cap = "Accuracy data for three age groups across three different conditions. Conditions varied by the number of times the child observed an unambigious novel label applied to the familiar object prior to the critical disambiguation trial. The dashed line corresponds to chance. Ranges are 95\\% CIs."}
mss <- e2_clean %>%
  group_by(age_group, cond, sub_num) %>%
  summarise(correct = mean(correct)) 

ms <- mss %>%
  multi_boot_standard(col = "correct", na.rm=TRUE)

ggplot(ms, aes(x = factor(age_group), y = mean, col = cond)) + 
  geom_hline(yintercept = .5, lty = 2) + 
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper), 
                  position = position_dodge(width = .1)) + 
  geom_line(aes(group = cond)) +
  xlab("Age (years)") + 
  ylim(0,1) + 
  ylab("Proportion correct") + 
  scale_color_solarized(name = "Condition", 
                        labels=c("1 label", "2 label", "3 label")) + 
  theme_classic() +
  ggtitle("Experiment 2")

```

```{r}
e2_clean$age_mo_c <- scale(e2_clean$age_mo, 
                           scale = FALSE, center = TRUE)
e2_clean$times_labeled_c <- scale(e2_clean$times_labeled, 
                                  scale = FALSE, center = TRUE)

m3 <- glmer(correct ~ age_mo_c * times_labeled_c  + 
               (times_labeled_c | sub_num), 
      family = "binomial", 
      data = e2_clean) %>%
      summary()

print_model3 <- m3$coefficients %>%
  data.frame() %>%
  stats::setNames(c("B", "SE", "Z", "p")) %>%
  rownames_to_column("term")  %>%
  mutate_at(2:5, function(x) {round(x, 2)}) %>%
  mutate(p_print = ifelse(p == 0, "< .001", p),
         pp_print = ifelse(p == 0, "< .001", paste0("= ", p)),
         pretty_model = paste0("B = ", B, ", SE = ", SE, 
                               ", Z = ", Z, ", p ", pp_print),
        term = c("(Intercept)",
                  "Age",
                  "Num. Labels Observed",
                  "Age x Num. Labels Observed")) %>%
  select(-p) %>%
  rename(p = "p_print") %>%
  select(term, everything(), -pp_print, -pretty_model)

kable(print_model3,
        row.names = F,
        format = "latex",
        booktabs = TRUE) %>%
        #caption = "Parameters of logistic mixed model predicting accuracy on disambiguation trials as a function of Age (months) and number of times a label for the familiar object was observed.") 
    kable_styling(font_size = 9)
```

We analyzed the results using a logistic mixed model to predict correct responses with age, number of labels, and their interaction as fixed effects, and participant as a random effect. Model results are shown in Table XYZ. There was a significant effect of age such that older children showed a stronger disambiguation bias and a  significant effect of number of labels, such that more training labels led to stronger disambiguation, but the interaction between age and number of labels was not significant.
